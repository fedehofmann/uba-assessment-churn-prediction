{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', 200) # Display all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cliente_vip</th>\n",
       "      <th>internet</th>\n",
       "      <th>cliente_edad</th>\n",
       "      <th>cliente_antiguedad</th>\n",
       "      <th>mrentabilidad</th>\n",
       "      <th>mrentabilidad_anual</th>\n",
       "      <th>mcomisiones</th>\n",
       "      <th>mactivos_margen</th>\n",
       "      <th>mpasivos_margen</th>\n",
       "      <th>cant_total_prod</th>\n",
       "      <th>tpaquete1</th>\n",
       "      <th>tpaquete2</th>\n",
       "      <th>tpaquete3</th>\n",
       "      <th>tpaquete4</th>\n",
       "      <th>tpaquete5</th>\n",
       "      <th>tpaquete6</th>\n",
       "      <th>tpaquete7</th>\n",
       "      <th>tpaquete8</th>\n",
       "      <th>tpaquete9</th>\n",
       "      <th>mdescubierto_preacordado</th>\n",
       "      <th>mcuentas_saldo</th>\n",
       "      <th>ctarjeta_debito_transacciones</th>\n",
       "      <th>mautoservicio</th>\n",
       "      <th>ctarjeta_visa</th>\n",
       "      <th>ctarjeta_visa_transacciones</th>\n",
       "      <th>mtarjeta_visa_consumo</th>\n",
       "      <th>ctarjeta_master</th>\n",
       "      <th>ctarjeta_master_transacciones</th>\n",
       "      <th>mtarjeta_master_consumo</th>\n",
       "      <th>cprestamos_personales</th>\n",
       "      <th>mprestamos_personales</th>\n",
       "      <th>cplazo_fijo</th>\n",
       "      <th>mplazo_fijo_dolares</th>\n",
       "      <th>mplazo_fijo_pesos</th>\n",
       "      <th>cfondos_comunes_inversion</th>\n",
       "      <th>mfondos_comunes_inversion_pesos</th>\n",
       "      <th>mfondos_comunes_inversion_dolares</th>\n",
       "      <th>ctitulos</th>\n",
       "      <th>mtitulos</th>\n",
       "      <th>cseguro_auto</th>\n",
       "      <th>cseguro_vivienda</th>\n",
       "      <th>cseguro_accidentes_personales</th>\n",
       "      <th>ccaja_seguridad</th>\n",
       "      <th>mbonos_corporativos</th>\n",
       "      <th>mmonedas_extranjeras</th>\n",
       "      <th>minversiones_otras</th>\n",
       "      <th>cplan_sueldo</th>\n",
       "      <th>mplan_sueldo</th>\n",
       "      <th>mplan_sueldo_manual</th>\n",
       "      <th>cplan_sueldo_transaccion</th>\n",
       "      <th>ccuenta_debitos_automaticos</th>\n",
       "      <th>mcuenta_debitos_automaticos</th>\n",
       "      <th>ctarjeta_visa_debitos_automaticos</th>\n",
       "      <th>mttarjeta_visa_debitos_automaticos</th>\n",
       "      <th>cpagodeservicios</th>\n",
       "      <th>mpagodeservicios</th>\n",
       "      <th>cpagomiscuentas</th>\n",
       "      <th>mpagomiscuentas</th>\n",
       "      <th>mcomisiones_mantenimiento</th>\n",
       "      <th>ccomisiones_otras</th>\n",
       "      <th>mcomisiones_otras</th>\n",
       "      <th>ccambio_monedas</th>\n",
       "      <th>ccambio_monedas_compra</th>\n",
       "      <th>mcambio_monedas_compra</th>\n",
       "      <th>ccambio_monedas_venta</th>\n",
       "      <th>mcambio_monedas_venta</th>\n",
       "      <th>ctransferencias_recibidas</th>\n",
       "      <th>mtransferencias_recibidas</th>\n",
       "      <th>ctransferencias_emitidas</th>\n",
       "      <th>mtransferencias_emitidas</th>\n",
       "      <th>cextraccion_autoservicio</th>\n",
       "      <th>mextraccion_autoservicio</th>\n",
       "      <th>ccheques_depositados</th>\n",
       "      <th>mcheques_depositados</th>\n",
       "      <th>ccheques_emitidos</th>\n",
       "      <th>mcheques_emitidos</th>\n",
       "      <th>ccheques_depositados_rechazados</th>\n",
       "      <th>mcheques_depositados_rechazados</th>\n",
       "      <th>ccheques_emitidos_rechazados</th>\n",
       "      <th>mcheques_emitidos_rechazados</th>\n",
       "      <th>thomebanking</th>\n",
       "      <th>chomebanking_transacciones</th>\n",
       "      <th>cautoservicio</th>\n",
       "      <th>cautoservicio_transacciones</th>\n",
       "      <th>tmovimientos_ultimos90dias</th>\n",
       "      <th>visa_marca_atraso</th>\n",
       "      <th>visa_mfinanciacion_limite</th>\n",
       "      <th>visa_msaldototal</th>\n",
       "      <th>visa_msaldopesos</th>\n",
       "      <th>visa_msaldodolares</th>\n",
       "      <th>visa_mconsumospesos</th>\n",
       "      <th>visa_mconsumosdolares</th>\n",
       "      <th>visa_mlimitecompra</th>\n",
       "      <th>visa_mpagado</th>\n",
       "      <th>visa_mpagospesos</th>\n",
       "      <th>visa_mpagosdolares</th>\n",
       "      <th>visa_mconsumototal</th>\n",
       "      <th>visa_cconsumos</th>\n",
       "      <th>visa_mpagominimo</th>\n",
       "      <th>clase_binaria</th>\n",
       "      <th>visa_tenure_days</th>\n",
       "      <th>tcuentas_2</th>\n",
       "      <th>visa_cuenta_estado_11.0</th>\n",
       "      <th>visa_cuenta_estado_12.0</th>\n",
       "      <th>visa_cuenta_estado_19.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>72</td>\n",
       "      <td>3296.69</td>\n",
       "      <td>14455.27</td>\n",
       "      <td>579.66</td>\n",
       "      <td>910.65</td>\n",
       "      <td>1411.60</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>-460.04</td>\n",
       "      <td>2</td>\n",
       "      <td>2574.00</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>19451.75</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>17091.34</td>\n",
       "      <td>3</td>\n",
       "      <td>73704.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>56580.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>68.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>579.66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63180.0</td>\n",
       "      <td>29994.31</td>\n",
       "      <td>32262.86</td>\n",
       "      <td>2830.47</td>\n",
       "      <td>14555.47</td>\n",
       "      <td>59.47</td>\n",
       "      <td>70200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-19632.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14555.47</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3837.6</td>\n",
       "      <td>0</td>\n",
       "      <td>4203</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>159</td>\n",
       "      <td>1032.18</td>\n",
       "      <td>10141.18</td>\n",
       "      <td>790.58</td>\n",
       "      <td>71.21</td>\n",
       "      <td>135.29</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>6301.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>174.33</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>833.97</td>\n",
       "      <td>4</td>\n",
       "      <td>790.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>351.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63180.0</td>\n",
       "      <td>182.45</td>\n",
       "      <td>213.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-11.55</td>\n",
       "      <td>4.22</td>\n",
       "      <td>70200.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2976.51</td>\n",
       "      <td>62.78</td>\n",
       "      <td>-11.55</td>\n",
       "      <td>2.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0</td>\n",
       "      <td>6859</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>299</td>\n",
       "      <td>-52.34</td>\n",
       "      <td>4752.64</td>\n",
       "      <td>236.08</td>\n",
       "      <td>-422.18</td>\n",
       "      <td>175.66</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>45.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>11670.93</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>236.08</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176904.0</td>\n",
       "      <td>10367.71</td>\n",
       "      <td>12130.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6788.67</td>\n",
       "      <td>0.00</td>\n",
       "      <td>196560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12753.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6788.67</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1977.3</td>\n",
       "      <td>0</td>\n",
       "      <td>10314</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>282</td>\n",
       "      <td>485.91</td>\n",
       "      <td>10676.87</td>\n",
       "      <td>1280.47</td>\n",
       "      <td>-1275.18</td>\n",
       "      <td>596.07</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>5429.85</td>\n",
       "      <td>4</td>\n",
       "      <td>4103.69</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>9840.21</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>12383.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10509.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5303.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2460.0</td>\n",
       "      <td>833.97</td>\n",
       "      <td>18</td>\n",
       "      <td>1280.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176904.0</td>\n",
       "      <td>6754.10</td>\n",
       "      <td>7433.72</td>\n",
       "      <td>468.57</td>\n",
       "      <td>2946.70</td>\n",
       "      <td>10.51</td>\n",
       "      <td>196560.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3685.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2946.70</td>\n",
       "      <td>5.0</td>\n",
       "      <td>573.3</td>\n",
       "      <td>0</td>\n",
       "      <td>3578</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>171</td>\n",
       "      <td>5878.27</td>\n",
       "      <td>24298.75</td>\n",
       "      <td>64.38</td>\n",
       "      <td>22.11</td>\n",
       "      <td>4947.03</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>563006.87</td>\n",
       "      <td>10</td>\n",
       "      <td>4313.45</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1496.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2171.89</td>\n",
       "      <td>1</td>\n",
       "      <td>339.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>64.38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>16160.54</td>\n",
       "      <td>5</td>\n",
       "      <td>4797.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44226.0</td>\n",
       "      <td>1316.65</td>\n",
       "      <td>1540.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1048.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>49140.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1861.64</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1048.32</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.7</td>\n",
       "      <td>0</td>\n",
       "      <td>7231</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cliente_vip  internet  cliente_edad  cliente_antiguedad  mrentabilidad  \\\n",
       "0            0         1            44                  72        3296.69   \n",
       "1            0         0            78                 159        1032.18   \n",
       "2            0         1            64                 299         -52.34   \n",
       "3            0         1            48                 282         485.91   \n",
       "4            0         1            45                 171        5878.27   \n",
       "\n",
       "   mrentabilidad_anual  mcomisiones  mactivos_margen  mpasivos_margen  \\\n",
       "0             14455.27       579.66           910.65          1411.60   \n",
       "1             10141.18       790.58            71.21           135.29   \n",
       "2              4752.64       236.08          -422.18           175.66   \n",
       "3             10676.87      1280.47         -1275.18           596.07   \n",
       "4             24298.75        64.38            22.11          4947.03   \n",
       "\n",
       "   cant_total_prod  tpaquete1  tpaquete2  tpaquete3  tpaquete4  tpaquete5  \\\n",
       "0               11          1          0          0          0          0   \n",
       "1                6          1          0          0          0          0   \n",
       "2                7          1          0          0          0          0   \n",
       "3                8          1          0          0          0          0   \n",
       "4                9          1          0          0          0          0   \n",
       "\n",
       "   tpaquete6  tpaquete7  tpaquete8  tpaquete9  mdescubierto_preacordado  \\\n",
       "0          0          0          0          0                      1.17   \n",
       "1          0          0          0          0                      1.17   \n",
       "2          0          0          0          0                      1.17   \n",
       "3          0          0          0          0                      1.17   \n",
       "4          0          0          0          0                      1.17   \n",
       "\n",
       "   mcuentas_saldo  ctarjeta_debito_transacciones  mautoservicio  \\\n",
       "0         -460.04                              2        2574.00   \n",
       "1         6301.72                              0           0.00   \n",
       "2           45.63                              0           0.00   \n",
       "3         5429.85                              4        4103.69   \n",
       "4       563006.87                             10        4313.45   \n",
       "\n",
       "   ctarjeta_visa  ctarjeta_visa_transacciones  mtarjeta_visa_consumo  \\\n",
       "0              1                           17               19451.75   \n",
       "1              1                            1                 174.33   \n",
       "2              1                            8               11670.93   \n",
       "3              1                            9                9840.21   \n",
       "4              1                            2                1496.03   \n",
       "\n",
       "   ctarjeta_master  ctarjeta_master_transacciones  mtarjeta_master_consumo  \\\n",
       "0                1                             18                 17091.34   \n",
       "1                1                              0                     0.00   \n",
       "2                1                              0                     0.00   \n",
       "3                1                             14                 12383.23   \n",
       "4                1                              0                     0.00   \n",
       "\n",
       "   cprestamos_personales  mprestamos_personales  cplazo_fijo  \\\n",
       "0                      3               73704.79            0   \n",
       "1                      0                   0.00            0   \n",
       "2                      0                   0.00            0   \n",
       "3                      0                   0.00            0   \n",
       "4                      0                   0.00            1   \n",
       "\n",
       "   mplazo_fijo_dolares  mplazo_fijo_pesos  cfondos_comunes_inversion  \\\n",
       "0                  0.0                0.0                          0   \n",
       "1                  0.0                0.0                          0   \n",
       "2                  0.0                0.0                          0   \n",
       "3                  0.0                0.0                          0   \n",
       "4             351000.0                0.0                          0   \n",
       "\n",
       "   mfondos_comunes_inversion_pesos  mfondos_comunes_inversion_dolares  \\\n",
       "0                              0.0                                0.0   \n",
       "1                              0.0                                0.0   \n",
       "2                              0.0                                0.0   \n",
       "3                              0.0                                0.0   \n",
       "4                              0.0                                0.0   \n",
       "\n",
       "   ctitulos  mtitulos  cseguro_auto  cseguro_vivienda  \\\n",
       "0         0      0.00             0                 1   \n",
       "1         0      0.00             0                 0   \n",
       "2         0      0.00             0                 0   \n",
       "3         3  10509.33             0                 0   \n",
       "4         0      0.00             0                 0   \n",
       "\n",
       "   cseguro_accidentes_personales  ccaja_seguridad  mbonos_corporativos  \\\n",
       "0                              0                0                    0   \n",
       "1                              0                0                    0   \n",
       "2                              0                0                    0   \n",
       "3                              0                0                    0   \n",
       "4                              0                0                    0   \n",
       "\n",
       "   mmonedas_extranjeras  minversiones_otras  cplan_sueldo  mplan_sueldo  \\\n",
       "0                     0                   0             1      56580.03   \n",
       "1                     0                   0             0          0.00   \n",
       "2                     0                   0             0          0.00   \n",
       "3                     0                   0             0          0.00   \n",
       "4                     0                   0             0          0.00   \n",
       "\n",
       "   mplan_sueldo_manual  cplan_sueldo_transaccion  ccuenta_debitos_automaticos  \\\n",
       "0                  0.0                         0                            1   \n",
       "1                  0.0                         0                            0   \n",
       "2                  0.0                         0                            0   \n",
       "3                  0.0                         0                            4   \n",
       "4                  0.0                         0                            0   \n",
       "\n",
       "   mcuenta_debitos_automaticos  ctarjeta_visa_debitos_automaticos  \\\n",
       "0                        68.94                                  0   \n",
       "1                         0.00                                  0   \n",
       "2                         0.00                                  0   \n",
       "3                      5303.31                                  0   \n",
       "4                         0.00                                  0   \n",
       "\n",
       "   mttarjeta_visa_debitos_automaticos  cpagodeservicios  mpagodeservicios  \\\n",
       "0                                 0.0                 0              0.00   \n",
       "1                                 0.0                 0              0.00   \n",
       "2                                 0.0                 0              0.00   \n",
       "3                                 0.0                 0              0.00   \n",
       "4                                 0.0                 7           2171.89   \n",
       "\n",
       "   cpagomiscuentas  mpagomiscuentas  mcomisiones_mantenimiento  \\\n",
       "0                0              0.0                       0.00   \n",
       "1                0              0.0                     833.97   \n",
       "2                0              0.0                       0.00   \n",
       "3                2           2460.0                     833.97   \n",
       "4                1            339.3                       0.00   \n",
       "\n",
       "   ccomisiones_otras  mcomisiones_otras  ccambio_monedas  \\\n",
       "0                 14             579.66                0   \n",
       "1                  4             790.58                0   \n",
       "2                  6             236.08                0   \n",
       "3                 18            1280.47                0   \n",
       "4                 12              64.38                0   \n",
       "\n",
       "   ccambio_monedas_compra  mcambio_monedas_compra  ccambio_monedas_venta  \\\n",
       "0                       0                     0.0                      0   \n",
       "1                       0                     0.0                      0   \n",
       "2                       0                     0.0                      0   \n",
       "3                       0                     0.0                      0   \n",
       "4                       0                     0.0                      0   \n",
       "\n",
       "   mcambio_monedas_venta  ctransferencias_recibidas  \\\n",
       "0                    0.0                          0   \n",
       "1                    0.0                          0   \n",
       "2                    0.0                          0   \n",
       "3                    0.0                          0   \n",
       "4                    0.0                          0   \n",
       "\n",
       "   mtransferencias_recibidas  ctransferencias_emitidas  \\\n",
       "0                        0.0                         0   \n",
       "1                        0.0                         1   \n",
       "2                        0.0                         0   \n",
       "3                        0.0                         0   \n",
       "4                        0.0                         2   \n",
       "\n",
       "   mtransferencias_emitidas  cextraccion_autoservicio  \\\n",
       "0                      0.00                         0   \n",
       "1                    351.00                         0   \n",
       "2                      0.00                         0   \n",
       "3                      0.00                         0   \n",
       "4                  16160.54                         5   \n",
       "\n",
       "   mextraccion_autoservicio  ccheques_depositados  mcheques_depositados  \\\n",
       "0                       0.0                     0                   0.0   \n",
       "1                       0.0                     0                   0.0   \n",
       "2                       0.0                     0                   0.0   \n",
       "3                       0.0                     0                   0.0   \n",
       "4                    4797.0                     0                   0.0   \n",
       "\n",
       "   ccheques_emitidos  mcheques_emitidos  ccheques_depositados_rechazados  \\\n",
       "0                  0                0.0                                0   \n",
       "1                  0                0.0                                0   \n",
       "2                  0                0.0                                0   \n",
       "3                  0                0.0                                0   \n",
       "4                  0                0.0                                0   \n",
       "\n",
       "   mcheques_depositados_rechazados  ccheques_emitidos_rechazados  \\\n",
       "0                              0.0                             0   \n",
       "1                              0.0                             0   \n",
       "2                              0.0                             0   \n",
       "3                              0.0                             0   \n",
       "4                              0.0                             0   \n",
       "\n",
       "   mcheques_emitidos_rechazados  thomebanking  chomebanking_transacciones  \\\n",
       "0                           0.0             0                           0   \n",
       "1                           0.0             0                           1   \n",
       "2                           0.0             1                           0   \n",
       "3                           0.0             1                          78   \n",
       "4                           0.0             1                           4   \n",
       "\n",
       "   cautoservicio  cautoservicio_transacciones  tmovimientos_ultimos90dias  \\\n",
       "0              0                            0                         116   \n",
       "1              0                            0                          17   \n",
       "2              0                            0                          10   \n",
       "3              0                            0                          85   \n",
       "4              0                            0                          94   \n",
       "\n",
       "   visa_marca_atraso  visa_mfinanciacion_limite  visa_msaldototal  \\\n",
       "0                0.0                    63180.0          29994.31   \n",
       "1                0.0                    63180.0            182.45   \n",
       "2                0.0                   176904.0          10367.71   \n",
       "3                0.0                   176904.0           6754.10   \n",
       "4                0.0                    44226.0           1316.65   \n",
       "\n",
       "   visa_msaldopesos  visa_msaldodolares  visa_mconsumospesos  \\\n",
       "0          32262.86             2830.47             14555.47   \n",
       "1            213.46                0.00               -11.55   \n",
       "2          12130.22                0.00              6788.67   \n",
       "3           7433.72              468.57              2946.70   \n",
       "4           1540.48                0.00              1048.32   \n",
       "\n",
       "   visa_mconsumosdolares  visa_mlimitecompra  visa_mpagado  visa_mpagospesos  \\\n",
       "0                  59.47             70200.0           0.0         -19632.60   \n",
       "1                   4.22             70200.0           0.0          -2976.51   \n",
       "2                   0.00            196560.0           0.0         -12753.00   \n",
       "3                  10.51            196560.0           0.0          -3685.76   \n",
       "4                   0.00             49140.0           0.0          -1861.64   \n",
       "\n",
       "   visa_mpagosdolares  visa_mconsumototal  visa_cconsumos  visa_mpagominimo  \\\n",
       "0                0.00            14555.47            13.0            3837.6   \n",
       "1               62.78              -11.55             2.0              35.1   \n",
       "2                0.00             6788.67             4.0            1977.3   \n",
       "3                0.00             2946.70             5.0             573.3   \n",
       "4                0.00             1048.32             1.0             128.7   \n",
       "\n",
       "   clase_binaria  visa_tenure_days  tcuentas_2  visa_cuenta_estado_11.0  \\\n",
       "0              0              4203       False                    False   \n",
       "1              0              6859       False                    False   \n",
       "2              0             10314       False                    False   \n",
       "3              0              3578       False                    False   \n",
       "4              0              7231       False                    False   \n",
       "\n",
       "   visa_cuenta_estado_12.0  visa_cuenta_estado_19.0  \n",
       "0                    False                    False  \n",
       "1                    False                    False  \n",
       "2                    False                    False  \n",
       "3                    False                    False  \n",
       "4                    False                    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_parquet(\"../data/processed/churn_prediction_dataset.parquet\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation AUC Scores: [0.93728772 0.94780681 0.92716024 0.93602409 0.92976706]\n",
      "Cross-Validation Accuracy Scores: [0.99362187 0.99432025 0.9940469  0.99422913 0.99407727]\n",
      "Mean AUC Score: 0.9356091861910848\n",
      "Mean Accuracy Score: 0.9940590838180787\n",
      "Validation Errors (AUC): [0.06271228 0.05219319 0.07283976 0.06397591 0.07023294]\n",
      "Mean Validation Error (AUC): 0.06439081380891525\n",
      "Validation Errors (Accuracy): [0.00637813 0.00567975 0.0059531  0.00577087 0.00592273]\n",
      "Mean Validation Error (Accuracy): 0.005940916181921274\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       1.00      1.00      1.00    163292\n",
      "       Churn       0.99      0.65      0.79      1329\n",
      "\n",
      "    accuracy                           1.00    164621\n",
      "   macro avg       1.00      0.83      0.89    164621\n",
      "weighted avg       1.00      1.00      1.00    164621\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# Features and target\n",
    "X = df.drop(columns=[\"clase_binaria\"])  # Exclude the target column\n",
    "y = df[\"clase_binaria\"]\n",
    "\n",
    "# Define the XGBoost model with class balancing\n",
    "xgb_model = xgb.XGBClassifier(scale_pos_weight=1, random_state=12, n_estimators=100)\n",
    "\n",
    "# Define StratifiedKFold for cross-validation\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=12)\n",
    "\n",
    "# Perform stratified cross-validation with AUC scoring\n",
    "cv_auc_scores = cross_val_score(xgb_model, X, y, cv=skf, scoring='roc_auc')  # Using AUC as the metric\n",
    "\n",
    "# Perform stratified cross-validation with Accuracy scoring\n",
    "cv_accuracy_scores = cross_val_score(xgb_model, X, y, cv=skf, scoring='accuracy')  # Using Accuracy as the metric\n",
    "\n",
    "# Print Cross-Validation AUC Scores\n",
    "print(\"Cross-Validation AUC Scores:\", cv_auc_scores)\n",
    "\n",
    "# Print Cross-Validation Accuracy Scores\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_accuracy_scores)\n",
    "\n",
    "# Calculate and print the Mean AUC Score\n",
    "print(\"Mean AUC Score:\", cv_auc_scores.mean())\n",
    "\n",
    "# Calculate and print the Mean Accuracy Score\n",
    "print(\"Mean Accuracy Score:\", cv_accuracy_scores.mean())\n",
    "\n",
    "# Calculate and print the validation errors (1 - AUC score)\n",
    "cv_auc_errors = 1 - cv_auc_scores\n",
    "print(\"Validation Errors (AUC):\", cv_auc_errors)\n",
    "print(\"Mean Validation Error (AUC):\", cv_auc_errors.mean())\n",
    "\n",
    "# Calculate and print the validation errors (1 - accuracy score)\n",
    "cv_accuracy_errors = 1 - cv_accuracy_scores\n",
    "print(\"Validation Errors (Accuracy):\", cv_accuracy_errors)\n",
    "print(\"Mean Validation Error (Accuracy):\", cv_accuracy_errors.mean())\n",
    "\n",
    "# Fit the XGBoost model on the entire dataset (optional, for evaluation purposes)\n",
    "xgb_model.fit(X, y)\n",
    "y_pred = xgb_model.predict(X)\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y, y_pred, target_names=[\"No Churn\", \"Churn\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cliente_vip</th>\n",
       "      <th>internet</th>\n",
       "      <th>cliente_edad</th>\n",
       "      <th>cliente_antiguedad</th>\n",
       "      <th>mrentabilidad</th>\n",
       "      <th>mrentabilidad_anual</th>\n",
       "      <th>mcomisiones</th>\n",
       "      <th>mactivos_margen</th>\n",
       "      <th>mpasivos_margen</th>\n",
       "      <th>cant_total_prod</th>\n",
       "      <th>tpaquete1</th>\n",
       "      <th>tpaquete2</th>\n",
       "      <th>tpaquete3</th>\n",
       "      <th>tpaquete4</th>\n",
       "      <th>tpaquete5</th>\n",
       "      <th>tpaquete6</th>\n",
       "      <th>tpaquete7</th>\n",
       "      <th>tpaquete8</th>\n",
       "      <th>tpaquete9</th>\n",
       "      <th>mdescubierto_preacordado</th>\n",
       "      <th>mcuentas_saldo</th>\n",
       "      <th>ctarjeta_debito_transacciones</th>\n",
       "      <th>mautoservicio</th>\n",
       "      <th>ctarjeta_visa</th>\n",
       "      <th>ctarjeta_visa_transacciones</th>\n",
       "      <th>mtarjeta_visa_consumo</th>\n",
       "      <th>ctarjeta_master</th>\n",
       "      <th>ctarjeta_master_transacciones</th>\n",
       "      <th>mtarjeta_master_consumo</th>\n",
       "      <th>cprestamos_personales</th>\n",
       "      <th>mprestamos_personales</th>\n",
       "      <th>cplazo_fijo</th>\n",
       "      <th>mplazo_fijo_dolares</th>\n",
       "      <th>mplazo_fijo_pesos</th>\n",
       "      <th>cfondos_comunes_inversion</th>\n",
       "      <th>mfondos_comunes_inversion_pesos</th>\n",
       "      <th>mfondos_comunes_inversion_dolares</th>\n",
       "      <th>ctitulos</th>\n",
       "      <th>mtitulos</th>\n",
       "      <th>cseguro_auto</th>\n",
       "      <th>cseguro_vivienda</th>\n",
       "      <th>cseguro_accidentes_personales</th>\n",
       "      <th>ccaja_seguridad</th>\n",
       "      <th>mbonos_corporativos</th>\n",
       "      <th>mmonedas_extranjeras</th>\n",
       "      <th>minversiones_otras</th>\n",
       "      <th>cplan_sueldo</th>\n",
       "      <th>mplan_sueldo</th>\n",
       "      <th>mplan_sueldo_manual</th>\n",
       "      <th>cplan_sueldo_transaccion</th>\n",
       "      <th>ccuenta_debitos_automaticos</th>\n",
       "      <th>mcuenta_debitos_automaticos</th>\n",
       "      <th>ctarjeta_visa_debitos_automaticos</th>\n",
       "      <th>mttarjeta_visa_debitos_automaticos</th>\n",
       "      <th>cpagodeservicios</th>\n",
       "      <th>mpagodeservicios</th>\n",
       "      <th>cpagomiscuentas</th>\n",
       "      <th>mpagomiscuentas</th>\n",
       "      <th>mcomisiones_mantenimiento</th>\n",
       "      <th>ccomisiones_otras</th>\n",
       "      <th>mcomisiones_otras</th>\n",
       "      <th>ccambio_monedas</th>\n",
       "      <th>ccambio_monedas_compra</th>\n",
       "      <th>mcambio_monedas_compra</th>\n",
       "      <th>ccambio_monedas_venta</th>\n",
       "      <th>mcambio_monedas_venta</th>\n",
       "      <th>ctransferencias_recibidas</th>\n",
       "      <th>mtransferencias_recibidas</th>\n",
       "      <th>ctransferencias_emitidas</th>\n",
       "      <th>mtransferencias_emitidas</th>\n",
       "      <th>cextraccion_autoservicio</th>\n",
       "      <th>mextraccion_autoservicio</th>\n",
       "      <th>ccheques_depositados</th>\n",
       "      <th>mcheques_depositados</th>\n",
       "      <th>ccheques_emitidos</th>\n",
       "      <th>mcheques_emitidos</th>\n",
       "      <th>ccheques_depositados_rechazados</th>\n",
       "      <th>mcheques_depositados_rechazados</th>\n",
       "      <th>ccheques_emitidos_rechazados</th>\n",
       "      <th>mcheques_emitidos_rechazados</th>\n",
       "      <th>thomebanking</th>\n",
       "      <th>chomebanking_transacciones</th>\n",
       "      <th>cautoservicio</th>\n",
       "      <th>cautoservicio_transacciones</th>\n",
       "      <th>tmovimientos_ultimos90dias</th>\n",
       "      <th>visa_marca_atraso</th>\n",
       "      <th>visa_mfinanciacion_limite</th>\n",
       "      <th>visa_msaldototal</th>\n",
       "      <th>visa_msaldopesos</th>\n",
       "      <th>visa_msaldodolares</th>\n",
       "      <th>visa_mconsumospesos</th>\n",
       "      <th>visa_mconsumosdolares</th>\n",
       "      <th>visa_mlimitecompra</th>\n",
       "      <th>visa_mpagado</th>\n",
       "      <th>visa_mpagospesos</th>\n",
       "      <th>visa_mpagosdolares</th>\n",
       "      <th>visa_mconsumototal</th>\n",
       "      <th>visa_cconsumos</th>\n",
       "      <th>visa_mpagominimo</th>\n",
       "      <th>visa_tenure_days</th>\n",
       "      <th>tcuentas_2</th>\n",
       "      <th>visa_cuenta_estado_11.0</th>\n",
       "      <th>visa_cuenta_estado_12.0</th>\n",
       "      <th>visa_cuenta_estado_19.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47532</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>209</td>\n",
       "      <td>1420.39</td>\n",
       "      <td>14893.02</td>\n",
       "      <td>178.00</td>\n",
       "      <td>752.43</td>\n",
       "      <td>309.44</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>-4129.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8174.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>127072.99</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27978.21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11</td>\n",
       "      <td>178.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>18837.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63180.00</td>\n",
       "      <td>7357.96</td>\n",
       "      <td>8608.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4193.12</td>\n",
       "      <td>6.04</td>\n",
       "      <td>70200.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-6647.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4193.12</td>\n",
       "      <td>6.0</td>\n",
       "      <td>854.1</td>\n",
       "      <td>6540</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64483</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>179</td>\n",
       "      <td>618.53</td>\n",
       "      <td>8029.68</td>\n",
       "      <td>273.59</td>\n",
       "      <td>-831.83</td>\n",
       "      <td>1126.65</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>24145.96</td>\n",
       "      <td>4</td>\n",
       "      <td>8877.59</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14314.31</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>9266.59</td>\n",
       "      <td>1</td>\n",
       "      <td>4368.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>32931.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>91.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>273.59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>3510.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88452.00</td>\n",
       "      <td>12280.45</td>\n",
       "      <td>14368.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4117.66</td>\n",
       "      <td>6.24</td>\n",
       "      <td>98280.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13967.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4117.66</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1076.4</td>\n",
       "      <td>6317</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41972</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>58</td>\n",
       "      <td>141</td>\n",
       "      <td>1023.99</td>\n",
       "      <td>99883.12</td>\n",
       "      <td>281.93</td>\n",
       "      <td>-708.40</td>\n",
       "      <td>1342.64</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>251176.89</td>\n",
       "      <td>10</td>\n",
       "      <td>2158.59</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>26146.51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>12676.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>6551.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>281.93</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>234.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2106.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>415588.56</td>\n",
       "      <td>22368.24</td>\n",
       "      <td>26170.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25571.28</td>\n",
       "      <td>2.67</td>\n",
       "      <td>461765.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-13827.80</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25571.28</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1275.3</td>\n",
       "      <td>5117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116588</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>118</td>\n",
       "      <td>324.60</td>\n",
       "      <td>3993.23</td>\n",
       "      <td>77.51</td>\n",
       "      <td>-59.63</td>\n",
       "      <td>270.82</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>22969.33</td>\n",
       "      <td>4</td>\n",
       "      <td>1922.91</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6498.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41940.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6258.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>77.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13349.70</td>\n",
       "      <td>6</td>\n",
       "      <td>17550.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50544.00</td>\n",
       "      <td>5679.64</td>\n",
       "      <td>6645.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2718.09</td>\n",
       "      <td>16.98</td>\n",
       "      <td>56160.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4345.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2718.09</td>\n",
       "      <td>10.0</td>\n",
       "      <td>397.8</td>\n",
       "      <td>5413</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75284</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>4076.93</td>\n",
       "      <td>17348.30</td>\n",
       "      <td>609.67</td>\n",
       "      <td>1209.81</td>\n",
       "      <td>1753.66</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>330116.57</td>\n",
       "      <td>8</td>\n",
       "      <td>15764.58</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1407.51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14207.97</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>75631.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5470.94</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3567.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>609.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>18098.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>88452.00</td>\n",
       "      <td>1238.48</td>\n",
       "      <td>1449.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1283.01</td>\n",
       "      <td>2.77</td>\n",
       "      <td>98280.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-52688.35</td>\n",
       "      <td>1158.69</td>\n",
       "      <td>1283.01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.6</td>\n",
       "      <td>6631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136807</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>57</td>\n",
       "      <td>4921.21</td>\n",
       "      <td>45194.81</td>\n",
       "      <td>3295.79</td>\n",
       "      <td>-526.33</td>\n",
       "      <td>1915.58</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>-6249.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>71826.97</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>51402.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1631.27</td>\n",
       "      <td>8</td>\n",
       "      <td>3295.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>570270.57</td>\n",
       "      <td>62612.52</td>\n",
       "      <td>72997.13</td>\n",
       "      <td>259.51</td>\n",
       "      <td>32998.34</td>\n",
       "      <td>1.70</td>\n",
       "      <td>633656.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-81900.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32998.34</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5522.4</td>\n",
       "      <td>3739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152818</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>44</td>\n",
       "      <td>1638.71</td>\n",
       "      <td>12765.37</td>\n",
       "      <td>239.47</td>\n",
       "      <td>-80.72</td>\n",
       "      <td>1276.65</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>53366.09</td>\n",
       "      <td>12</td>\n",
       "      <td>16239.77</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8461.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>63731.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2862.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3060.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>239.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63180.00</td>\n",
       "      <td>7445.46</td>\n",
       "      <td>8711.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>205.48</td>\n",
       "      <td>16.62</td>\n",
       "      <td>70200.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-16537.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>205.48</td>\n",
       "      <td>7.0</td>\n",
       "      <td>959.4</td>\n",
       "      <td>3342</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69852</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>172</td>\n",
       "      <td>473.45</td>\n",
       "      <td>5718.16</td>\n",
       "      <td>102.05</td>\n",
       "      <td>-112.27</td>\n",
       "      <td>429.70</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>5739.90</td>\n",
       "      <td>10</td>\n",
       "      <td>11821.51</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8126.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>12200.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49844.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2131.74</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>11653.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10</td>\n",
       "      <td>107.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2925.00</td>\n",
       "      <td>4</td>\n",
       "      <td>6552.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252720.00</td>\n",
       "      <td>7005.53</td>\n",
       "      <td>8196.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3407.09</td>\n",
       "      <td>6.06</td>\n",
       "      <td>280800.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5815.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3407.09</td>\n",
       "      <td>7.0</td>\n",
       "      <td>655.2</td>\n",
       "      <td>7111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130886</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>95</td>\n",
       "      <td>2721.93</td>\n",
       "      <td>67208.06</td>\n",
       "      <td>38.01</td>\n",
       "      <td>-6.08</td>\n",
       "      <td>2300.03</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>127544.27</td>\n",
       "      <td>31</td>\n",
       "      <td>16286.02</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>697.70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>301.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62154.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3067.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "      <td>38.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6435.00</td>\n",
       "      <td>7</td>\n",
       "      <td>19305.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252720.00</td>\n",
       "      <td>603.49</td>\n",
       "      <td>706.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>280800.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-706.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.1</td>\n",
       "      <td>4574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139288</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>78</td>\n",
       "      <td>1601.95</td>\n",
       "      <td>18970.98</td>\n",
       "      <td>1125.41</td>\n",
       "      <td>-58.59</td>\n",
       "      <td>465.89</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.17</td>\n",
       "      <td>16627.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6344.41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1979.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6903.39</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1196.91</td>\n",
       "      <td>10</td>\n",
       "      <td>1126.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>9711.00</td>\n",
       "      <td>3</td>\n",
       "      <td>11700.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>19656.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6552.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>252720.00</td>\n",
       "      <td>5428.00</td>\n",
       "      <td>6350.76</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2974.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>280800.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8111.29</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2974.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>257.4</td>\n",
       "      <td>4382</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32925 rows  104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cliente_vip  internet  cliente_edad  cliente_antiguedad  \\\n",
       "47532             0         0            57                 209   \n",
       "64483             0         1            60                 179   \n",
       "41972             0         1            58                 141   \n",
       "116588            0         1            27                 118   \n",
       "75284             0         1            35                 168   \n",
       "...             ...       ...           ...                 ...   \n",
       "136807            0         1            41                  57   \n",
       "152818            0         1            28                  44   \n",
       "69852             0         1            40                 172   \n",
       "130886            0         1            57                  95   \n",
       "139288            0         1            35                  78   \n",
       "\n",
       "        mrentabilidad  mrentabilidad_anual  mcomisiones  mactivos_margen  \\\n",
       "47532         1420.39             14893.02       178.00           752.43   \n",
       "64483          618.53              8029.68       273.59          -831.83   \n",
       "41972         1023.99             99883.12       281.93          -708.40   \n",
       "116588         324.60              3993.23        77.51           -59.63   \n",
       "75284         4076.93             17348.30       609.67          1209.81   \n",
       "...               ...                  ...          ...              ...   \n",
       "136807        4921.21             45194.81      3295.79          -526.33   \n",
       "152818        1638.71             12765.37       239.47           -80.72   \n",
       "69852          473.45              5718.16       102.05          -112.27   \n",
       "130886        2721.93             67208.06        38.01            -6.08   \n",
       "139288        1601.95             18970.98      1125.41           -58.59   \n",
       "\n",
       "        mpasivos_margen  cant_total_prod  tpaquete1  tpaquete2  tpaquete3  \\\n",
       "47532            309.44               11          1          0          0   \n",
       "64483           1126.65               10          1          0          0   \n",
       "41972           1342.64                8          1          0          0   \n",
       "116588           270.82                7          1          0          0   \n",
       "75284           1753.66                6          1          0          0   \n",
       "...                 ...              ...        ...        ...        ...   \n",
       "136807          1915.58                6          1          0          0   \n",
       "152818          1276.65                7          1          0          0   \n",
       "69852            429.70               10          1          0          0   \n",
       "130886          2300.03                7          1          0          0   \n",
       "139288           465.89                7          1          0          0   \n",
       "\n",
       "        tpaquete4  tpaquete5  tpaquete6  tpaquete7  tpaquete8  tpaquete9  \\\n",
       "47532           0          0          0          0          0          0   \n",
       "64483           0          0          0          0          0          0   \n",
       "41972           0          0          0          0          0          0   \n",
       "116588          0          0          0          0          0          0   \n",
       "75284           0          0          0          0          0          0   \n",
       "...           ...        ...        ...        ...        ...        ...   \n",
       "136807          0          0          0          0          0          0   \n",
       "152818          0          0          0          0          0          0   \n",
       "69852           0          0          0          0          0          0   \n",
       "130886          0          0          0          0          0          0   \n",
       "139288          0          0          0          0          0          0   \n",
       "\n",
       "        mdescubierto_preacordado  mcuentas_saldo  \\\n",
       "47532                       1.17        -4129.18   \n",
       "64483                       1.17        24145.96   \n",
       "41972                       1.17       251176.89   \n",
       "116588                      1.17        22969.33   \n",
       "75284                       1.17       330116.57   \n",
       "...                          ...             ...   \n",
       "136807                      1.17        -6249.74   \n",
       "152818                      1.17        53366.09   \n",
       "69852                       1.17         5739.90   \n",
       "130886                      1.17       127544.27   \n",
       "139288                      1.17        16627.82   \n",
       "\n",
       "        ctarjeta_debito_transacciones  mautoservicio  ctarjeta_visa  \\\n",
       "47532                               0           0.00              1   \n",
       "64483                               4        8877.59              1   \n",
       "41972                              10        2158.59              1   \n",
       "116588                              4        1922.91              1   \n",
       "75284                               8       15764.58              1   \n",
       "...                               ...            ...            ...   \n",
       "136807                              0           0.00              1   \n",
       "152818                             12       16239.77              1   \n",
       "69852                              10       11821.51              1   \n",
       "130886                             31       16286.02              1   \n",
       "139288                              0           0.00              1   \n",
       "\n",
       "        ctarjeta_visa_transacciones  mtarjeta_visa_consumo  ctarjeta_master  \\\n",
       "47532                             9                8174.26                1   \n",
       "64483                            15               14314.31                1   \n",
       "41972                            40               26146.51                1   \n",
       "116588                           11                6498.25                1   \n",
       "75284                             3                1407.51                1   \n",
       "...                             ...                    ...              ...   \n",
       "136807                           52               71826.97                1   \n",
       "152818                            8                8461.20                1   \n",
       "69852                             9                8126.30                1   \n",
       "130886                            1                 697.70                1   \n",
       "139288                            3                6344.41                1   \n",
       "\n",
       "        ctarjeta_master_transacciones  mtarjeta_master_consumo  \\\n",
       "47532                               0                     0.00   \n",
       "64483                               7                  9266.59   \n",
       "41972                               0                     0.00   \n",
       "116588                              0                     0.00   \n",
       "75284                               2                 14207.97   \n",
       "...                               ...                      ...   \n",
       "136807                              9                 51402.55   \n",
       "152818                              0                     0.00   \n",
       "69852                               0                     0.00   \n",
       "130886                              1                   301.27   \n",
       "139288                              2                  1979.39   \n",
       "\n",
       "        cprestamos_personales  mprestamos_personales  cplazo_fijo  \\\n",
       "47532                       3              127072.99            0   \n",
       "64483                       1                4368.60            0   \n",
       "41972                       0                   0.00            0   \n",
       "116588                      0                   0.00            0   \n",
       "75284                       0                   0.00            0   \n",
       "...                       ...                    ...          ...   \n",
       "136807                      0                   0.00            0   \n",
       "152818                      0                   0.00            0   \n",
       "69852                       0                   0.00            0   \n",
       "130886                      0                   0.00            0   \n",
       "139288                      0                   0.00            0   \n",
       "\n",
       "        mplazo_fijo_dolares  mplazo_fijo_pesos  cfondos_comunes_inversion  \\\n",
       "47532                   0.0                0.0                          0   \n",
       "64483                   0.0                0.0                          0   \n",
       "41972                   0.0                0.0                          0   \n",
       "116588                  0.0                0.0                          0   \n",
       "75284                   0.0                0.0                          0   \n",
       "...                     ...                ...                        ...   \n",
       "136807                  0.0                0.0                          0   \n",
       "152818                  0.0                0.0                          0   \n",
       "69852                   0.0                0.0                          1   \n",
       "130886                  0.0                0.0                          0   \n",
       "139288                  0.0                0.0                          0   \n",
       "\n",
       "        mfondos_comunes_inversion_pesos  mfondos_comunes_inversion_dolares  \\\n",
       "47532                              0.00                                0.0   \n",
       "64483                              0.00                                0.0   \n",
       "41972                              0.00                                0.0   \n",
       "116588                             0.00                                0.0   \n",
       "75284                              0.00                                0.0   \n",
       "...                                 ...                                ...   \n",
       "136807                             0.00                                0.0   \n",
       "152818                             0.00                                0.0   \n",
       "69852                          12200.77                                0.0   \n",
       "130886                             0.00                                0.0   \n",
       "139288                             0.00                                0.0   \n",
       "\n",
       "        ctitulos  mtitulos  cseguro_auto  cseguro_vivienda  \\\n",
       "47532          0       0.0             0                 0   \n",
       "64483          0       0.0             0                 0   \n",
       "41972          0       0.0             0                 0   \n",
       "116588         0       0.0             0                 0   \n",
       "75284          0       0.0             0                 0   \n",
       "...          ...       ...           ...               ...   \n",
       "136807         0       0.0             0                 0   \n",
       "152818         0       0.0             0                 0   \n",
       "69852          0       0.0             0                 0   \n",
       "130886         0       0.0             0                 0   \n",
       "139288         0       0.0             0                 0   \n",
       "\n",
       "        cseguro_accidentes_personales  ccaja_seguridad  mbonos_corporativos  \\\n",
       "47532                               1                0                    0   \n",
       "64483                               0                0                    0   \n",
       "41972                               0                1                    0   \n",
       "116588                              0                0                    0   \n",
       "75284                               0                0                    0   \n",
       "...                               ...              ...                  ...   \n",
       "136807                              0                0                    0   \n",
       "152818                              0                0                    0   \n",
       "69852                               0                0                    0   \n",
       "130886                              0                0                    0   \n",
       "139288                              0                0                    0   \n",
       "\n",
       "        mmonedas_extranjeras  minversiones_otras  cplan_sueldo  mplan_sueldo  \\\n",
       "47532                      0                   0             2      27978.21   \n",
       "64483                      0                   0             1      32931.99   \n",
       "41972                      0                   0             0          0.00   \n",
       "116588                     0                   0             1      41940.99   \n",
       "75284                      0                   0             1      75631.14   \n",
       "...                      ...                 ...           ...           ...   \n",
       "136807                     0                   0             0          0.00   \n",
       "152818                     0                   0             2      63731.29   \n",
       "69852                      0                   0             1      49844.34   \n",
       "130886                     0                   0             1      62154.96   \n",
       "139288                     0                   0             0          0.00   \n",
       "\n",
       "        mplan_sueldo_manual  cplan_sueldo_transaccion  \\\n",
       "47532                   0.0                         0   \n",
       "64483                   0.0                         0   \n",
       "41972                   0.0                         0   \n",
       "116588                  0.0                         0   \n",
       "75284                   0.0                         0   \n",
       "...                     ...                       ...   \n",
       "136807                  0.0                         0   \n",
       "152818                  0.0                         0   \n",
       "69852                   0.0                         0   \n",
       "130886                  0.0                         0   \n",
       "139288                  0.0                         0   \n",
       "\n",
       "        ccuenta_debitos_automaticos  mcuenta_debitos_automaticos  \\\n",
       "47532                             1                        22.23   \n",
       "64483                             2                        91.18   \n",
       "41972                             8                     12676.79   \n",
       "116588                            1                        22.23   \n",
       "75284                             3                      5470.94   \n",
       "...                             ...                          ...   \n",
       "136807                            0                         0.00   \n",
       "152818                            2                      2862.52   \n",
       "69852                             3                      2131.74   \n",
       "130886                            1                      3067.76   \n",
       "139288                            2                      6903.39   \n",
       "\n",
       "        ctarjeta_visa_debitos_automaticos  mttarjeta_visa_debitos_automaticos  \\\n",
       "47532                                   0                                 0.0   \n",
       "64483                                   0                                 0.0   \n",
       "41972                                   0                                 0.0   \n",
       "116588                                  0                                 0.0   \n",
       "75284                                   0                                 0.0   \n",
       "...                                   ...                                 ...   \n",
       "136807                                  0                                 0.0   \n",
       "152818                                  0                                 0.0   \n",
       "69852                                   0                                 0.0   \n",
       "130886                                  0                                 0.0   \n",
       "139288                                  0                                 0.0   \n",
       "\n",
       "        cpagodeservicios  mpagodeservicios  cpagomiscuentas  mpagomiscuentas  \\\n",
       "47532                  0               0.0                0             0.00   \n",
       "64483                  0               0.0                0             0.00   \n",
       "41972                  0               0.0                4          6551.66   \n",
       "116588                 0               0.0                5          6258.42   \n",
       "75284                  0               0.0                2          3567.02   \n",
       "...                  ...               ...              ...              ...   \n",
       "136807                 0               0.0                0             0.00   \n",
       "152818                 0               0.0                1          3060.60   \n",
       "69852                  0               0.0                5         11653.43   \n",
       "130886                 0               0.0                0             0.00   \n",
       "139288                 0               0.0                0             0.00   \n",
       "\n",
       "        mcomisiones_mantenimiento  ccomisiones_otras  mcomisiones_otras  \\\n",
       "47532                        0.00                 11             178.00   \n",
       "64483                        0.00                 10             273.59   \n",
       "41972                        0.00                  6             281.93   \n",
       "116588                       0.00                 10              77.51   \n",
       "75284                        0.00                 12             609.67   \n",
       "...                           ...                ...                ...   \n",
       "136807                    1631.27                  8            3295.79   \n",
       "152818                       0.00                 10             239.47   \n",
       "69852                        0.00                 10             107.47   \n",
       "130886                       0.00                  6              38.01   \n",
       "139288                    1196.91                 10            1126.40   \n",
       "\n",
       "        ccambio_monedas  ccambio_monedas_compra  mcambio_monedas_compra  \\\n",
       "47532                 0                       0                     0.0   \n",
       "64483                 0                       0                     0.0   \n",
       "41972                 1                       1                   234.0   \n",
       "116588                0                       0                     0.0   \n",
       "75284                 0                       0                     0.0   \n",
       "...                 ...                     ...                     ...   \n",
       "136807                0                       0                     0.0   \n",
       "152818                0                       0                     0.0   \n",
       "69852                 0                       0                     0.0   \n",
       "130886                0                       0                     0.0   \n",
       "139288                0                       0                     0.0   \n",
       "\n",
       "        ccambio_monedas_venta  mcambio_monedas_venta  \\\n",
       "47532                       0                    0.0   \n",
       "64483                       0                    0.0   \n",
       "41972                       0                    0.0   \n",
       "116588                      0                    0.0   \n",
       "75284                       0                    0.0   \n",
       "...                       ...                    ...   \n",
       "136807                      0                    0.0   \n",
       "152818                      0                    0.0   \n",
       "69852                       0                    0.0   \n",
       "130886                      0                    0.0   \n",
       "139288                      0                    0.0   \n",
       "\n",
       "        ctransferencias_recibidas  mtransferencias_recibidas  \\\n",
       "47532                           0                        0.0   \n",
       "64483                           0                        0.0   \n",
       "41972                           0                        0.0   \n",
       "116588                          0                        0.0   \n",
       "75284                           0                        0.0   \n",
       "...                           ...                        ...   \n",
       "136807                          0                        0.0   \n",
       "152818                          0                        0.0   \n",
       "69852                           0                        0.0   \n",
       "130886                          0                        0.0   \n",
       "139288                          0                        0.0   \n",
       "\n",
       "        ctransferencias_emitidas  mtransferencias_emitidas  \\\n",
       "47532                          0                      0.00   \n",
       "64483                          0                      0.00   \n",
       "41972                          1                   2106.00   \n",
       "116588                         3                  13349.70   \n",
       "75284                          2                  18098.58   \n",
       "...                          ...                       ...   \n",
       "136807                         0                      0.00   \n",
       "152818                         0                      0.00   \n",
       "69852                          1                   2925.00   \n",
       "130886                         1                   6435.00   \n",
       "139288                         1                   9711.00   \n",
       "\n",
       "        cextraccion_autoservicio  mextraccion_autoservicio  \\\n",
       "47532                         12                   18837.0   \n",
       "64483                          2                    3510.0   \n",
       "41972                          0                       0.0   \n",
       "116588                         6                   17550.0   \n",
       "75284                          0                       0.0   \n",
       "...                          ...                       ...   \n",
       "136807                         0                       0.0   \n",
       "152818                         3                   11700.0   \n",
       "69852                          4                    6552.0   \n",
       "130886                         7                   19305.0   \n",
       "139288                         3                   11700.0   \n",
       "\n",
       "        ccheques_depositados  mcheques_depositados  ccheques_emitidos  \\\n",
       "47532                      0                   0.0                  0   \n",
       "64483                      0                   0.0                  0   \n",
       "41972                      0                   0.0                  0   \n",
       "116588                     0                   0.0                  0   \n",
       "75284                      0                   0.0                  0   \n",
       "...                      ...                   ...                ...   \n",
       "136807                     0                   0.0                  0   \n",
       "152818                     0                   0.0                  0   \n",
       "69852                      0                   0.0                  0   \n",
       "130886                     0                   0.0                  0   \n",
       "139288                     0                   0.0                  3   \n",
       "\n",
       "        mcheques_emitidos  ccheques_depositados_rechazados  \\\n",
       "47532                 0.0                                0   \n",
       "64483                 0.0                                0   \n",
       "41972                 0.0                                0   \n",
       "116588                0.0                                0   \n",
       "75284                 0.0                                0   \n",
       "...                   ...                              ...   \n",
       "136807                0.0                                0   \n",
       "152818                0.0                                0   \n",
       "69852                 0.0                                0   \n",
       "130886                0.0                                0   \n",
       "139288            19656.0                                0   \n",
       "\n",
       "        mcheques_depositados_rechazados  ccheques_emitidos_rechazados  \\\n",
       "47532                               0.0                             0   \n",
       "64483                               0.0                             0   \n",
       "41972                               0.0                             0   \n",
       "116588                              0.0                             0   \n",
       "75284                               0.0                             0   \n",
       "...                                 ...                           ...   \n",
       "136807                              0.0                             0   \n",
       "152818                              0.0                             0   \n",
       "69852                               0.0                             0   \n",
       "130886                              0.0                             0   \n",
       "139288                              0.0                             1   \n",
       "\n",
       "        mcheques_emitidos_rechazados  thomebanking  \\\n",
       "47532                            0.0             0   \n",
       "64483                            0.0             0   \n",
       "41972                            0.0             1   \n",
       "116588                           0.0             1   \n",
       "75284                            0.0             1   \n",
       "...                              ...           ...   \n",
       "136807                           0.0             1   \n",
       "152818                           0.0             1   \n",
       "69852                            0.0             1   \n",
       "130886                           0.0             1   \n",
       "139288                        6552.0             1   \n",
       "\n",
       "        chomebanking_transacciones  cautoservicio  \\\n",
       "47532                            0              0   \n",
       "64483                            0              0   \n",
       "41972                            5              0   \n",
       "116588                          37              0   \n",
       "75284                           24              0   \n",
       "...                            ...            ...   \n",
       "136807                          12              0   \n",
       "152818                           1              0   \n",
       "69852                            6              0   \n",
       "130886                           1              0   \n",
       "139288                           1              0   \n",
       "\n",
       "        cautoservicio_transacciones  tmovimientos_ultimos90dias  \\\n",
       "47532                             0                          84   \n",
       "64483                             0                          77   \n",
       "41972                             0                         180   \n",
       "116588                            0                         147   \n",
       "75284                             0                          76   \n",
       "...                             ...                         ...   \n",
       "136807                            0                         121   \n",
       "152818                            0                          79   \n",
       "69852                             0                         114   \n",
       "130886                            0                         117   \n",
       "139288                            0                          69   \n",
       "\n",
       "        visa_marca_atraso  visa_mfinanciacion_limite  visa_msaldototal  \\\n",
       "47532                 0.0                   63180.00           7357.96   \n",
       "64483                 0.0                   88452.00          12280.45   \n",
       "41972                 0.0                  415588.56          22368.24   \n",
       "116588                0.0                   50544.00           5679.64   \n",
       "75284                 0.0                   88452.00           1238.48   \n",
       "...                   ...                        ...               ...   \n",
       "136807                0.0                  570270.57          62612.52   \n",
       "152818                0.0                   63180.00           7445.46   \n",
       "69852                 0.0                  252720.00           7005.53   \n",
       "130886                0.0                  252720.00            603.49   \n",
       "139288                0.0                  252720.00           5428.00   \n",
       "\n",
       "        visa_msaldopesos  visa_msaldodolares  visa_mconsumospesos  \\\n",
       "47532            8608.81                0.00              4193.12   \n",
       "64483           14368.12                0.00              4117.66   \n",
       "41972           26170.84                0.00             25571.28   \n",
       "116588           6645.17                0.00              2718.09   \n",
       "75284            1449.02                0.00              1283.01   \n",
       "...                  ...                 ...                  ...   \n",
       "136807          72997.13              259.51             32998.34   \n",
       "152818           8711.18                0.00               205.48   \n",
       "69852            8196.47                0.00              3407.09   \n",
       "130886            706.08                0.00                 0.00   \n",
       "139288           6350.76                0.00              2974.12   \n",
       "\n",
       "        visa_mconsumosdolares  visa_mlimitecompra  visa_mpagado  \\\n",
       "47532                    6.04            70200.00           0.0   \n",
       "64483                    6.24            98280.00           0.0   \n",
       "41972                    2.67           461765.07           0.0   \n",
       "116588                  16.98            56160.00           0.0   \n",
       "75284                    2.77            98280.00           0.0   \n",
       "...                       ...                 ...           ...   \n",
       "136807                   1.70           633656.86           0.0   \n",
       "152818                  16.62            70200.00           0.0   \n",
       "69852                    6.06           280800.00           0.0   \n",
       "130886                   0.00           280800.00           0.0   \n",
       "139288                   0.00           280800.00           0.0   \n",
       "\n",
       "        visa_mpagospesos  visa_mpagosdolares  visa_mconsumototal  \\\n",
       "47532           -6647.68                0.00             4193.12   \n",
       "64483          -13967.41                0.00             4117.66   \n",
       "41972          -13827.80                0.00            25571.28   \n",
       "116588          -4345.83                0.00             2718.09   \n",
       "75284          -52688.35             1158.69             1283.01   \n",
       "...                  ...                 ...                 ...   \n",
       "136807         -81900.00                0.00            32998.34   \n",
       "152818         -16537.42                0.00              205.48   \n",
       "69852           -5815.35                0.00             3407.09   \n",
       "130886           -706.08                0.00                0.00   \n",
       "139288          -8111.29                0.00             2974.12   \n",
       "\n",
       "        visa_cconsumos  visa_mpagominimo  visa_tenure_days  tcuentas_2  \\\n",
       "47532              6.0             854.1              6540           0   \n",
       "64483              6.0            1076.4              6317           0   \n",
       "41972             40.0            1275.3              5117           0   \n",
       "116588            10.0             397.8              5413           0   \n",
       "75284              4.0              93.6              6631           0   \n",
       "...                ...               ...               ...         ...   \n",
       "136807            15.0            5522.4              3739           0   \n",
       "152818             7.0             959.4              3342           0   \n",
       "69852              7.0             655.2              7111           0   \n",
       "130886             0.0              35.1              4574           0   \n",
       "139288             2.0             257.4              4382           0   \n",
       "\n",
       "        visa_cuenta_estado_11.0  visa_cuenta_estado_12.0  \\\n",
       "47532                         0                        0   \n",
       "64483                         0                        0   \n",
       "41972                         0                        0   \n",
       "116588                        0                        0   \n",
       "75284                         0                        0   \n",
       "...                         ...                      ...   \n",
       "136807                        0                        0   \n",
       "152818                        0                        0   \n",
       "69852                         0                        0   \n",
       "130886                        0                        0   \n",
       "139288                        0                        0   \n",
       "\n",
       "        visa_cuenta_estado_19.0  \n",
       "47532                         0  \n",
       "64483                         0  \n",
       "41972                         0  \n",
       "116588                        0  \n",
       "75284                         0  \n",
       "...                         ...  \n",
       "136807                        0  \n",
       "152818                        0  \n",
       "69852                         0  \n",
       "130886                        0  \n",
       "139288                        0  \n",
       "\n",
       "[32925 rows x 104 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean columns (bool) need to be converted to integers for SHAP to process them:\n",
    "X = X.astype({col: 'int64' for col in X.select_dtypes(include=['bool']).columns})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add SHAP graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "                Predicted No   Predicted Yes\n",
      "Actual No     TN = 163286    FP = 6\n",
      "Actual Yes    FN = 463    TP = 866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Generate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y, y_pred)\n",
    "\n",
    "# Print the confusion matrix with labels\n",
    "print(\"Confusion Matrix:\")\n",
    "print(f\"                Predicted No   Predicted Yes\")\n",
    "print(f\"Actual No     TN = {conf_matrix[0, 0]}    FP = {conf_matrix[0, 1]}\")\n",
    "print(f\"Actual Yes    FN = {conf_matrix[1, 0]}    TP = {conf_matrix[1, 1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[32635    24]\n",
      " [  160   106]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    No Churn       1.00      1.00      1.00     32659\n",
      "       Churn       0.82      0.40      0.54       266\n",
      "\n",
      "    accuracy                           0.99     32925\n",
      "   macro avg       0.91      0.70      0.77     32925\n",
      "weighted avg       0.99      0.99      0.99     32925\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.9432\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12, stratify=y)\n",
    "\n",
    "# Train the model on the training set\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]  # For ROC AUC\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"No Churn\", \"Churn\"]))\n",
    "\n",
    "# Calculate and print ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"\\nROC AUC Score: {roc_auc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cost-benefit values\n",
    "benefit_tp = 100   # Benefit of correctly predicting churn\n",
    "cost_fn = -500     # Cost of missing a churner\n",
    "cost_fp = -20      # Cost of wrongly targeting a non-churner\n",
    "benefit_tn = 0     # No benefit or cost for correctly predicting no churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.03\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate the net benefit for different thresholds\n",
    "thresholds = np.linspace(0, 1, 101)  # 101 thresholds from 0 to 1\n",
    "net_benefits = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    # Apply the threshold\n",
    "    y_pred_adjusted = (y_pred_proba >= threshold).astype(int)\n",
    "    \n",
    "    # Calculate confusion matrix components\n",
    "    tp = ((y_pred_adjusted == 1) & (y_test == 1)).sum()\n",
    "    fn = ((y_pred_adjusted == 0) & (y_test == 1)).sum()\n",
    "    fp = ((y_pred_adjusted == 1) & (y_test == 0)).sum()\n",
    "    tn = ((y_pred_adjusted == 0) & (y_test == 0)).sum()\n",
    "    \n",
    "    # Compute net benefit\n",
    "    net_benefit = (benefit_tp * tp + benefit_tn * tn + cost_fp * fp + cost_fn * fn)\n",
    "    net_benefits.append(net_benefit)\n",
    "\n",
    "# Find the threshold with the maximum net benefit\n",
    "optimal_threshold = thresholds[np.argmax(net_benefits)]\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Define cost-benefit values\n",
    "benefit_tp = 100\n",
    "cost_fn = -500\n",
    "cost_fp = -20\n",
    "benefit_tn = 0\n",
    "\n",
    "# Create sample weights\n",
    "sample_weights = np.where(y_train == 1, -cost_fn, -cost_fp)\n",
    "\n",
    "# Train XGBoost model with sample weights\n",
    "xgb_model = XGBClassifier(scale_pos_weight=1, random_state=12, n_estimators=100)\n",
    "xgb_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = xgb_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31603  1058]\n",
      " [  257     7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98     32661\n",
      "           1       0.01      0.03      0.01       264\n",
      "\n",
      "    accuracy                           0.96     32925\n",
      "   macro avg       0.50      0.50      0.50     32925\n",
      "weighted avg       0.98      0.96      0.97     32925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Adjust predictions using the optimal threshold\n",
    "y_pred_final = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "\n",
    "# Evaluate the refined model\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred_final))\n",
    "print(classification_report(y_test, y_pred_final))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-21 16:24:27,572] A new study created in memory with name: no-name-55a10a31-f8d3-4911-b5f9-89263e6df459\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:24:31,277] Trial 0 finished with value: 0.9381419805462873 and parameters: {'n_estimators': 86, 'max_depth': 4, 'learning_rate': 0.23640770434116967, 'subsample': 0.6339753842490661, 'colsample_bytree': 0.8842283875462347, 'gamma': 1.6590650825682323, 'reg_alpha': 1.140994046610594, 'reg_lambda': 5.5167504186535705, 'scale_pos_weight': 9.101867506072514}. Best is trial 0 with value: 0.9381419805462873.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:24:35,864] Trial 1 finished with value: 0.9401377472915462 and parameters: {'n_estimators': 158, 'max_depth': 3, 'learning_rate': 0.045455320241336486, 'subsample': 0.89829280370604, 'colsample_bytree': 0.8620826503673441, 'gamma': 1.3841469440697511, 'reg_alpha': 3.3184694990924566, 'reg_lambda': 0.49945498492002804, 'scale_pos_weight': 6.914385199840209}. Best is trial 1 with value: 0.9401377472915462.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:24:43,857] Trial 2 finished with value: 0.936842252282718 and parameters: {'n_estimators': 279, 'max_depth': 3, 'learning_rate': 0.2502537006996664, 'subsample': 0.8396502727604469, 'colsample_bytree': 0.6360754284895277, 'gamma': 1.0838317887747224, 'reg_alpha': 3.2156431570679302, 'reg_lambda': 9.926243943393995, 'scale_pos_weight': 5.249534127554828}. Best is trial 1 with value: 0.9401377472915462.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:24:50,047] Trial 3 finished with value: 0.9400010689630847 and parameters: {'n_estimators': 271, 'max_depth': 3, 'learning_rate': 0.25438897857617276, 'subsample': 0.9400479270742121, 'colsample_bytree': 0.6221621798815028, 'gamma': 1.9057459915884434, 'reg_alpha': 5.239228036214108, 'reg_lambda': 5.655180587283992, 'scale_pos_weight': 2.897726838597166}. Best is trial 1 with value: 0.9401377472915462.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:24:54,876] Trial 4 finished with value: 0.9398898699955863 and parameters: {'n_estimators': 134, 'max_depth': 4, 'learning_rate': 0.2234240716580423, 'subsample': 0.8382762420711791, 'colsample_bytree': 0.991468308636256, 'gamma': 0.18992010284485994, 'reg_alpha': 7.129834335966412, 'reg_lambda': 3.1199134715519783, 'scale_pos_weight': 5.228768170303192}. Best is trial 1 with value: 0.9401377472915462.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:24:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:25:03,602] Trial 5 finished with value: 0.9415267680596345 and parameters: {'n_estimators': 280, 'max_depth': 4, 'learning_rate': 0.10268858651705318, 'subsample': 0.671703320804659, 'colsample_bytree': 0.7281255089021458, 'gamma': 1.428630662466216, 'reg_alpha': 1.6001745897227992, 'reg_lambda': 2.021843053004051, 'scale_pos_weight': 2.185499608186853}. Best is trial 5 with value: 0.9415267680596345.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:25:08,110] Trial 6 finished with value: 0.9408489347102496 and parameters: {'n_estimators': 139, 'max_depth': 8, 'learning_rate': 0.2527105656071352, 'subsample': 0.6853183260574386, 'colsample_bytree': 0.9323211899261884, 'gamma': 3.911541840553231, 'reg_alpha': 2.7651196548205172, 'reg_lambda': 8.4567606982542, 'scale_pos_weight': 1.455036337560231}. Best is trial 5 with value: 0.9415267680596345.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:25:16,247] Trial 7 finished with value: 0.9413633438284977 and parameters: {'n_estimators': 144, 'max_depth': 9, 'learning_rate': 0.02593255153824071, 'subsample': 0.9612544561083847, 'colsample_bytree': 0.756062302128046, 'gamma': 1.4260826621225653, 'reg_alpha': 7.71015069792731, 'reg_lambda': 1.9839564867809623, 'scale_pos_weight': 3.1635697599965513}. Best is trial 5 with value: 0.9415267680596345.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:25:22,616] Trial 8 finished with value: 0.9423637010908197 and parameters: {'n_estimators': 167, 'max_depth': 5, 'learning_rate': 0.06153623580419109, 'subsample': 0.772741841648191, 'colsample_bytree': 0.9086695299961272, 'gamma': 0.04480938742464469, 'reg_alpha': 3.185474360924201, 'reg_lambda': 1.0951216721915258, 'scale_pos_weight': 3.912413782250062}. Best is trial 8 with value: 0.9423637010908197.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:25:28,817] Trial 9 finished with value: 0.9403614176169259 and parameters: {'n_estimators': 127, 'max_depth': 8, 'learning_rate': 0.18026990825221162, 'subsample': 0.7552434932419794, 'colsample_bytree': 0.8186303481888924, 'gamma': 4.886565210712133, 'reg_alpha': 4.0228148603900795, 'reg_lambda': 5.698740421371811, 'scale_pos_weight': 7.8134293057669275}. Best is trial 8 with value: 0.9423637010908197.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:25:37,392] Trial 10 finished with value: 0.9402852237682516 and parameters: {'n_estimators': 221, 'max_depth': 6, 'learning_rate': 0.09912505165200206, 'subsample': 0.7493624998679631, 'colsample_bytree': 0.990625764360155, 'gamma': 3.04301226526446, 'reg_alpha': 9.902788840404668, 'reg_lambda': 0.05738378018525836, 'scale_pos_weight': 4.237030463586278}. Best is trial 8 with value: 0.9423637010908197.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:25:46,571] Trial 11 finished with value: 0.9363447234344443 and parameters: {'n_estimators': 211, 'max_depth': 6, 'learning_rate': 0.10294888797696092, 'subsample': 0.6123928283818826, 'colsample_bytree': 0.7355019641709513, 'gamma': 0.4254961301090463, 'reg_alpha': 1.1298715496575875, 'reg_lambda': 2.67936249335821, 'scale_pos_weight': 1.0835351520952115}. Best is trial 8 with value: 0.9423637010908197.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:25:55,254] Trial 12 finished with value: 0.9402812305050018 and parameters: {'n_estimators': 224, 'max_depth': 5, 'learning_rate': 0.0937552780224526, 'subsample': 0.7007133329610719, 'colsample_bytree': 0.6866320553173476, 'gamma': 2.655789774586375, 'reg_alpha': 0.25784905886584375, 'reg_lambda': 3.7437641663670385, 'scale_pos_weight': 2.916187164635501}. Best is trial 8 with value: 0.9423637010908197.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:25:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:02,695] Trial 13 finished with value: 0.938289321174031 and parameters: {'n_estimators': 197, 'max_depth': 5, 'learning_rate': 0.13699018947877395, 'subsample': 0.7702944838998018, 'colsample_bytree': 0.7956903145296348, 'gamma': 0.6663385225231189, 'reg_alpha': 5.21554774018894, 'reg_lambda': 1.2831459416058646, 'scale_pos_weight': 4.04798122952852}. Best is trial 8 with value: 0.9423637010908197.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:05,571] Trial 14 finished with value: 0.9350166235507968 and parameters: {'n_estimators': 52, 'max_depth': 5, 'learning_rate': 0.0664425361997878, 'subsample': 0.6856053715087979, 'colsample_bytree': 0.7047119412750876, 'gamma': 0.08088762626177859, 'reg_alpha': 2.110238877811971, 'reg_lambda': 4.0301080197517365, 'scale_pos_weight': 1.720067133638104}. Best is trial 8 with value: 0.9423637010908197.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:15,056] Trial 15 finished with value: 0.9381053676207033 and parameters: {'n_estimators': 298, 'max_depth': 7, 'learning_rate': 0.1571649162736975, 'subsample': 0.822065580039379, 'colsample_bytree': 0.9082034801920282, 'gamma': 2.1543443795947783, 'reg_alpha': 1.8122821773615465, 'reg_lambda': 1.6136337838444814, 'scale_pos_weight': 6.668562353849525}. Best is trial 8 with value: 0.9423637010908197.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:24,582] Trial 16 finished with value: 0.9249492651101707 and parameters: {'n_estimators': 244, 'max_depth': 10, 'learning_rate': 0.2981577835497117, 'subsample': 0.7231424613322426, 'colsample_bytree': 0.8286923479731039, 'gamma': 0.9046966777398752, 'reg_alpha': 0.05075025091663954, 'reg_lambda': 7.018931904693171, 'scale_pos_weight': 4.095848500941503}. Best is trial 8 with value: 0.9423637010908197.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:30,526] Trial 17 finished with value: 0.9426890421850572 and parameters: {'n_estimators': 180, 'max_depth': 4, 'learning_rate': 0.06275595223872991, 'subsample': 0.6407146814298702, 'colsample_bytree': 0.9455056393189084, 'gamma': 3.24628726345868, 'reg_alpha': 4.058061389980914, 'reg_lambda': 4.288144720822787, 'scale_pos_weight': 2.114846950713862}. Best is trial 17 with value: 0.9426890421850572.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:38,457] Trial 18 finished with value: 0.9359573857493482 and parameters: {'n_estimators': 178, 'max_depth': 7, 'learning_rate': 0.010431309767484048, 'subsample': 0.8664384878973103, 'colsample_bytree': 0.9581736085126504, 'gamma': 3.4679888895081374, 'reg_alpha': 6.3639780448061725, 'reg_lambda': 7.579350760866964, 'scale_pos_weight': 6.13923299866963}. Best is trial 17 with value: 0.9426890421850572.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:43,093] Trial 19 finished with value: 0.9435720077365041 and parameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.06360500546786668, 'subsample': 0.7925231934966257, 'colsample_bytree': 0.9516132188568334, 'gamma': 4.135689937932744, 'reg_alpha': 4.269469779030872, 'reg_lambda': 4.262171480466699, 'scale_pos_weight': 2.3952123164856607}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:47,258] Trial 20 finished with value: 0.9424412074131986 and parameters: {'n_estimators': 102, 'max_depth': 6, 'learning_rate': 0.12901251884567827, 'subsample': 0.99653915088521, 'colsample_bytree': 0.951891609444243, 'gamma': 4.39133966333413, 'reg_alpha': 4.146452272156518, 'reg_lambda': 4.3418471984618305, 'scale_pos_weight': 2.359084054752316}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:51,509] Trial 21 finished with value: 0.9432341402208861 and parameters: {'n_estimators': 103, 'max_depth': 6, 'learning_rate': 0.13896055273632366, 'subsample': 0.9798906621969623, 'colsample_bytree': 0.9489420377335985, 'gamma': 4.571895778313086, 'reg_alpha': 4.63830792911495, 'reg_lambda': 4.467525536500918, 'scale_pos_weight': 2.1392250065750313}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:55,072] Trial 22 finished with value: 0.9431774761692173 and parameters: {'n_estimators': 103, 'max_depth': 4, 'learning_rate': 0.18105668419916357, 'subsample': 0.8986788308556749, 'colsample_bytree': 0.9549588346589958, 'gamma': 4.1326805820607255, 'reg_alpha': 6.106280241855979, 'reg_lambda': 4.728979678064717, 'scale_pos_weight': 2.150289164244134}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:26:58,940] Trial 23 finished with value: 0.9414881465614107 and parameters: {'n_estimators': 95, 'max_depth': 6, 'learning_rate': 0.1762549643860604, 'subsample': 0.9200471701784404, 'colsample_bytree': 0.8535993406994339, 'gamma': 4.163357003800018, 'reg_alpha': 5.815376708339193, 'reg_lambda': 6.607551335775497, 'scale_pos_weight': 3.394733455341216}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:26:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:01,956] Trial 24 finished with value: 0.9392689604142882 and parameters: {'n_estimators': 118, 'max_depth': 5, 'learning_rate': 0.20539739424233502, 'subsample': 0.9981575140785589, 'colsample_bytree': 0.9926232786869394, 'gamma': 4.932143916165384, 'reg_alpha': 8.422727269921275, 'reg_lambda': 4.832973775906309, 'scale_pos_weight': 1.3926643937720038}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:04,819] Trial 25 finished with value: 0.9434911368871584 and parameters: {'n_estimators': 66, 'max_depth': 4, 'learning_rate': 0.1972564404932989, 'subsample': 0.8837343949542544, 'colsample_bytree': 0.9095216129514883, 'gamma': 4.504023419914433, 'reg_alpha': 6.266579959712724, 'reg_lambda': 2.7003505920288635, 'scale_pos_weight': 4.713239631345061}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:08,488] Trial 26 finished with value: 0.943519944579722 and parameters: {'n_estimators': 63, 'max_depth': 7, 'learning_rate': 0.12460443521782204, 'subsample': 0.8051594776970273, 'colsample_bytree': 0.9070500477867527, 'gamma': 4.564819156486646, 'reg_alpha': 4.676507190293323, 'reg_lambda': 3.0431361683481954, 'scale_pos_weight': 4.728918123615807}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:08] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:12,561] Trial 27 finished with value: 0.9427423703764811 and parameters: {'n_estimators': 65, 'max_depth': 8, 'learning_rate': 0.12140544481711191, 'subsample': 0.8059081456036042, 'colsample_bytree': 0.9056127086529319, 'gamma': 3.62624377604816, 'reg_alpha': 7.003282844943577, 'reg_lambda': 3.087986223855153, 'scale_pos_weight': 4.9452909085880705}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:13] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:16,234] Trial 28 finished with value: 0.9429655991062171 and parameters: {'n_estimators': 66, 'max_depth': 7, 'learning_rate': 0.20368602891832632, 'subsample': 0.867261314585429, 'colsample_bytree': 0.8640429062239419, 'gamma': 4.605620483230448, 'reg_alpha': 8.865910448840488, 'reg_lambda': 2.5501746567494585, 'scale_pos_weight': 5.858464618565071}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:21,220] Trial 29 finished with value: 0.9390950654897887 and parameters: {'n_estimators': 80, 'max_depth': 9, 'learning_rate': 0.15692697180357562, 'subsample': 0.7925770701812813, 'colsample_bytree': 0.8866206468678157, 'gamma': 3.895379178900489, 'reg_alpha': 5.575510645971733, 'reg_lambda': 3.3989297182714404, 'scale_pos_weight': 7.861044140199825}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:25,058] Trial 30 finished with value: 0.9381601588971179 and parameters: {'n_estimators': 75, 'max_depth': 7, 'learning_rate': 0.2799759842782879, 'subsample': 0.862894945023317, 'colsample_bytree': 0.7885892848065092, 'gamma': 2.708889783818663, 'reg_alpha': 4.808206080836273, 'reg_lambda': 5.3110637839269295, 'scale_pos_weight': 4.516674186526162}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:28,083] Trial 31 finished with value: 0.9428840345934122 and parameters: {'n_estimators': 51, 'max_depth': 6, 'learning_rate': 0.1418189363993155, 'subsample': 0.9712128008051886, 'colsample_bytree': 0.92141931166915, 'gamma': 4.648112079383219, 'reg_alpha': 4.4967499282823855, 'reg_lambda': 6.20410657773038, 'scale_pos_weight': 3.511120492209133}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:32,593] Trial 32 finished with value: 0.9432051038952766 and parameters: {'n_estimators': 116, 'max_depth': 5, 'learning_rate': 0.0812871585337234, 'subsample': 0.8935959312632797, 'colsample_bytree': 0.8825601408478343, 'gamma': 4.432118117111049, 'reg_alpha': 6.878123411536141, 'reg_lambda': 2.531825725267071, 'scale_pos_weight': 9.989617525277707}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:36,426] Trial 33 finished with value: 0.9402254428624595 and parameters: {'n_estimators': 78, 'max_depth': 6, 'learning_rate': 0.20616532488478273, 'subsample': 0.7990219875852078, 'colsample_bytree': 0.9601034233324993, 'gamma': 4.984872166600816, 'reg_alpha': 3.6934593343565063, 'reg_lambda': 3.7819227126813337, 'scale_pos_weight': 4.898101533778687}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:39,522] Trial 34 finished with value: 0.9348965099076467 and parameters: {'n_estimators': 94, 'max_depth': 3, 'learning_rate': 0.04178818435337012, 'subsample': 0.941577040205176, 'colsample_bytree': 0.9741413716885944, 'gamma': 3.8355588575208737, 'reg_alpha': 4.749236412195814, 'reg_lambda': 4.8756100234126745, 'scale_pos_weight': 2.633088151871005}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:43,163] Trial 35 finished with value: 0.9429385376505678 and parameters: {'n_estimators': 108, 'max_depth': 3, 'learning_rate': 0.1676595597089506, 'subsample': 0.8475804810674863, 'colsample_bytree': 0.8882646247305128, 'gamma': 4.251019120284902, 'reg_alpha': 6.323087182490383, 'reg_lambda': 3.4316444392876226, 'scale_pos_weight': 5.70266403352259}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:45] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:46] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:46,774] Trial 36 finished with value: 0.940872922160521 and parameters: {'n_estimators': 88, 'max_depth': 4, 'learning_rate': 0.1200849280453201, 'subsample': 0.8979380684248115, 'colsample_bytree': 0.929667769842626, 'gamma': 4.559916866078104, 'reg_alpha': 2.61297844154706, 'reg_lambda': 0.6401296722670242, 'scale_pos_weight': 6.467050201324836}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:47] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:48] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:50] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:50,896] Trial 37 finished with value: 0.9386560479372749 and parameters: {'n_estimators': 65, 'max_depth': 7, 'learning_rate': 0.21982449243797375, 'subsample': 0.8289476836411084, 'colsample_bytree': 0.8585115771260883, 'gamma': 3.5500414124371638, 'reg_alpha': 5.264844152259232, 'reg_lambda': 2.937547750037017, 'scale_pos_weight': 7.362921201297644}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:51] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:52] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:53] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:27:55,472] Trial 38 finished with value: 0.941174929865895 and parameters: {'n_estimators': 148, 'max_depth': 3, 'learning_rate': 0.19346516974855027, 'subsample': 0.7214108080439767, 'colsample_bytree': 0.9755928336162946, 'gamma': 4.754776713184394, 'reg_alpha': 7.554967949483053, 'reg_lambda': 2.0008565178400173, 'scale_pos_weight': 4.886950694963002}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:55] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:56] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:57] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:58] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:27:59] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:00,416] Trial 39 finished with value: 0.9409665812003452 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.14615858814031166, 'subsample': 0.9228579995356723, 'colsample_bytree': 0.8299915009565126, 'gamma': 3.937307792415548, 'reg_alpha': 3.669343771325724, 'reg_lambda': 5.539228854256743, 'scale_pos_weight': 5.470109358730664}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:00] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:01] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:03,186] Trial 40 finished with value: 0.9424676481271858 and parameters: {'n_estimators': 51, 'max_depth': 4, 'learning_rate': 0.23347247565978968, 'subsample': 0.8147933745284937, 'colsample_bytree': 0.9313849682741799, 'gamma': 3.0309597275566365, 'reg_alpha': 2.909921242686393, 'reg_lambda': 4.4659498551773416, 'scale_pos_weight': 3.4945082598881454}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:03] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:05] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:06] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:07,700] Trial 41 finished with value: 0.9426387444955973 and parameters: {'n_estimators': 113, 'max_depth': 5, 'learning_rate': 0.07959663763055183, 'subsample': 0.8890498359892424, 'colsample_bytree': 0.8795671009433953, 'gamma': 4.430261897686506, 'reg_alpha': 6.92745133700644, 'reg_lambda': 2.249923405682477, 'scale_pos_weight': 9.645952154705386}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:07] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:09] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:10] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:11] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:13,925] Trial 42 finished with value: 0.9419415738612382 and parameters: {'n_estimators': 156, 'max_depth': 5, 'learning_rate': 0.08175630293477802, 'subsample': 0.781333939537196, 'colsample_bytree': 0.9030137262222604, 'gamma': 4.442545596487851, 'reg_alpha': 6.538345376331129, 'reg_lambda': 2.52945735333574, 'scale_pos_weight': 8.672694458509275}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:14] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:15] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:16] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:17] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:18,378] Trial 43 finished with value: 0.9420832664052176 and parameters: {'n_estimators': 87, 'max_depth': 6, 'learning_rate': 0.11238731504700947, 'subsample': 0.9615065046153256, 'colsample_bytree': 0.873966075933445, 'gamma': 4.221657215576084, 'reg_alpha': 7.664685383184188, 'reg_lambda': 3.4367904547115917, 'scale_pos_weight': 8.542078073404506}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:18] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:19] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:20] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:21] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:22] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:22,995] Trial 44 finished with value: 0.9414716146890955 and parameters: {'n_estimators': 134, 'max_depth': 4, 'learning_rate': 0.042597605906766686, 'subsample': 0.8478335249569379, 'colsample_bytree': 0.6047798720018044, 'gamma': 4.735090574725606, 'reg_alpha': 5.72246461633468, 'reg_lambda': 1.3788791342444418, 'scale_pos_weight': 4.515263439242852}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:23] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:24] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:25] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:26] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:27] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:28,583] Trial 45 finished with value: 0.9422411233776818 and parameters: {'n_estimators': 128, 'max_depth': 6, 'learning_rate': 0.08147693787798135, 'subsample': 0.92131233781689, 'colsample_bytree': 0.8487900632280743, 'gamma': 3.9776161811706587, 'reg_alpha': 4.530586319709294, 'reg_lambda': 4.003991972202226, 'scale_pos_weight': 9.768908041707702}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:28] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:29] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:31] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:31,761] Trial 46 finished with value: 0.9420889350414494 and parameters: {'n_estimators': 69, 'max_depth': 5, 'learning_rate': 0.1087782483635858, 'subsample': 0.7491668202354858, 'colsample_bytree': 0.9406275164511754, 'gamma': 3.693349116957192, 'reg_alpha': 5.228100316806893, 'reg_lambda': 2.8718171718112186, 'scale_pos_weight': 1.6817298600426493}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:32] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:33] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:34] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:35] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:36,727] Trial 47 finished with value: 0.9423320734020292 and parameters: {'n_estimators': 90, 'max_depth': 8, 'learning_rate': 0.05230643609038538, 'subsample': 0.8842370619249786, 'colsample_bytree': 0.9737206833628052, 'gamma': 3.2999816501068406, 'reg_alpha': 8.276305437762067, 'reg_lambda': 1.7823493349043251, 'scale_pos_weight': 2.7230250911775564}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:36] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:37] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:38] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:39] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:40,791] Trial 48 finished with value: 0.9416034635777166 and parameters: {'n_estimators': 104, 'max_depth': 5, 'learning_rate': 0.09193640375517552, 'subsample': 0.9529857652201985, 'colsample_bytree': 0.9176782892890841, 'gamma': 2.045892786876921, 'reg_alpha': 3.4569086333348915, 'reg_lambda': 9.089577493138535, 'scale_pos_weight': 1.0350838473798718}. Best is trial 19 with value: 0.9435720077365041.\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:41] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:42] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:43] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "[I 2024-11-21 16:28:43,761] Trial 49 finished with value: 0.9411187942421264 and parameters: {'n_estimators': 59, 'max_depth': 4, 'learning_rate': 0.13660997946863257, 'subsample': 0.9786019186926422, 'colsample_bytree': 0.8953892717240871, 'gamma': 1.7094171886627465, 'reg_alpha': 6.703784507740693, 'reg_lambda': 0.8667874054700273, 'scale_pos_weight': 3.8433495569180103}. Best is trial 19 with value: 0.9435720077365041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'n_estimators': 112, 'max_depth': 5, 'learning_rate': 0.06360500546786668, 'subsample': 0.7925231934966257, 'colsample_bytree': 0.9516132188568334, 'gamma': 4.135689937932744, 'reg_alpha': 4.269469779030872, 'reg_lambda': 4.262171480466699, 'scale_pos_weight': 2.3952123164856607}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juanignaciomonge/Desktop/Repositories/uba-assessment-churn-prediction/venv_tp_final_ds/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [16:28:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC on test set: 0.9408077923912915\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "# Split dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Define the objective function\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 300),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 10),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0, 5),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 0, 10),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 0, 10),\n",
    "        \"scale_pos_weight\": trial.suggest_float(\"scale_pos_weight\", 1, 10),\n",
    "    }\n",
    "\n",
    "    # Create the model\n",
    "    model = XGBClassifier(**params, random_state=12, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "    \n",
    "    # Cross-validation score\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring=\"roc_auc\")\n",
    "    return np.mean(cv_scores)\n",
    "\n",
    "# Create the study\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters:\", study.best_params)\n",
    "\n",
    "# Train the final model with the best parameters\n",
    "best_params = study.best_params\n",
    "final_model = XGBClassifier(**best_params, random_state=12, use_label_encoder=False, eval_metric=\"logloss\")\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = final_model.predict_proba(X_test)[:, 1]\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(\"ROC AUC on test set:\", roc_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = xgb_model.predict_proba(X_test)[:, 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_final = (y_pred_proba >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32494   171]\n",
      " [   35   225]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     32665\n",
      "           1       0.57      0.87      0.69       260\n",
      "\n",
      "    accuracy                           0.99     32925\n",
      "   macro avg       0.78      0.93      0.84     32925\n",
      "weighted avg       1.00      0.99      0.99     32925\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred_final))\n",
    "print(classification_report(y_test, y_pred_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_tp_final_ds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
